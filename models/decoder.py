import torch
import torch.nn as nn
from torch.nn import functional as F
from attention import SelfAttention

class VAEResiualBlock(nn.Module):
    def __init__(self):
        super().__init__()
        
        # TODO: Implemet residual block

class VAEAttentionBlock(nn.Module):
    def __init__(self):
        super().__init__()
        
        # TODO: Implemet attention block